{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "mount_file_id": "1NGJqCQpyVojCh6DX26ni0JOUcBfSBnIO",
      "authorship_tag": "ABX9TyN9EBKSxfwlU0XQTFj2sWng",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshsinha-12/IITP_CS_Sem1/blob/main/CS_Python4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ignore, it's for Mine the model"
      ],
      "metadata": {
        "id": "4YR2CeYzMKdW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "yZJpn486A0my",
        "outputId": "13c35df9-dab7-49df-e945-ac9b59e60e31"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-27a2c8422c6d>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Passing each CSV file in the defined function to generate prices for each stock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mstock_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstock_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/mine-the-model-2023/Upload-Dataset/TRAIN'"
          ]
        }
      ],
      "source": [
        "### Importing necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from prophet import Prophet\n",
        "\n",
        "def predictor(path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # This particular model only requires Date and Closing Price as feature and label\n",
        "    df = df[['Date', 'Close']]\n",
        "    df.columns = ['ds', 'y']\n",
        "\n",
        "    # Creating a model instance and training it on the train data\n",
        "    model = Prophet(daily_seasonality=True)\n",
        "    model.fit(df)\n",
        "\n",
        "    # Predicting closing price for the next 100 days\n",
        "    prediction_dates = model.make_future_dataframe(periods=100)\n",
        "    prediction_dates = prediction_dates.tail(100)\n",
        "    predictions = model.predict(prediction_dates)  # predictions is also a dataframe\n",
        "\n",
        "    # Creating the required format for the submission file\n",
        "    pred_df = predictions[['ds', 'yhat']]\n",
        "    pred_df.columns = ['Date', 'Price']\n",
        "\n",
        "    ids = []\n",
        "    for index, row in pred_df.iterrows():\n",
        "        ID = f\"{os.path.splitext(os.path.basename(path))[0]}_#{index + 1}\"\n",
        "        ids.append(ID)\n",
        "\n",
        "    pred_df['Date'] = ids\n",
        "\n",
        "    return pred_df\n",
        "\n",
        "# Specifying the folder path in which CSV files are stored\n",
        "folder_path = \"/kaggle/input/mine-the-model-2023/Upload-Dataset/TRAIN\"\n",
        "dfs = []\n",
        "\n",
        "# Passing each CSV file in the defined function to generate prices for each stock\n",
        "for filename in os.listdir(folder_path):\n",
        "    stock_df = os.path.join(folder_path, filename)\n",
        "    dfs.append(predictor(stock_df))\n",
        "\n",
        "# Concatenating the predicted data into one CSV file and saving it\n",
        "dfs_concat = pd.concat(dfs)\n",
        "dfs_concat.columns = ['ID', 'Price']\n",
        "dfs_concat.to_csv('Submission_prophet.csv', index=False)\n",
        "\n",
        "# Visualizing Predicted Data for one stock\n",
        "plt.plot(dfs_concat['ID'][0:100], dfs_concat['Price'][0:100])\n",
        "plt.title('Closing Price v/s Time', size=20)\n",
        "plt.xticks(c='white')\n",
        "plt.xlabel('Date', size=15)\n",
        "plt.ylabel('Closing Price', size=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jata sequence of a Figo Naki sequence take as input the first element of sequence. For example one, one, the next element would be some of previous two elements, generate the sequence till a limited say 30."
      ],
      "metadata": {
        "id": "kLDo37bZOEt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = 1\n",
        "n = int(input(\"Enter the number:\"))\n",
        "if n < 0:\n",
        "  print(\"Enter a positive value\")\n",
        "else:\n",
        "  for i in range(1, n+1):\n",
        "   f = f*i\n",
        "  print(\"Factorial of\",n,\"is:\",f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCvhgmmeOOt1",
        "outputId": "55189ccb-c530-4824-ef03-74c0cfe0b062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number:-4\n",
            "Enter a positive value\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pattern(rows, columns):\n",
        "  for i in range(rows):\n",
        "    for i in range(columns):\n",
        "      print(\"*\", end = \" \")\n",
        "    print(\"\\n\")\n",
        "\n",
        "pattern(3,4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR5guz0-TMcD",
        "outputId": "2eda1e80-deb2-4bbf-9dc5-0a3481df31a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* * * * \n",
            "\n",
            "* * * * \n",
            "\n",
            "* * * * \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pattern(rows, columns):\n",
        "  for i in range(rows):\n",
        "    for i in range(columns):\n",
        "      print(\"*\", end = \" \")\n",
        "    print(\"\\n\")\n",
        "\n",
        "pattern(3,4)\n",
        "\n",
        "***\n",
        "* *\n",
        "* *\n",
        "*** row horizontal, column vertical"
      ],
      "metadata": {
        "id": "jKmxf8YcViz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### Importing necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from prophet import Prophet\n",
        "\n",
        "def predictor(path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(\"/kaggle/input/mine-the-model-2023/Upload-Dataset/TRAIN/003.csv\")\n",
        "\n",
        "    df = df[['Date', 'Close']]\n",
        "    df.columns = ['ds', 'y']\n",
        "\n",
        "    # Creating a model instance and training it on the train data\n",
        "    model = Prophet(daily_seasonality=True)\n",
        "    model.fit(df)\n",
        "\n",
        "    # Predicting closing price for the next 100 days\n",
        "    prediction_dates = model.make_future_dataframe(periods=100)\n",
        "    prediction_dates = prediction_dates.tail(100)\n",
        "    predictions = model.predict(prediction_dates)  # predictions is also a dataframe\n",
        "\n",
        "    # Creating the required format for the submission file\n",
        "    pred_df = predictions[['ds', 'yhat']]\n",
        "    pred_df.columns = ['Date', 'Price']\n",
        "\n",
        "    ids = []\n",
        "    for index, row in pred_df.iterrows():\n",
        "        ID = f\"{os.path.splitext(os.path.basename(path))[0]}_#{index + 1}\"\n",
        "        ids.append(ID)\n",
        "    # Creating a copy of the DataFrame and modifying it\n",
        "    pred_df = pred_df.copy()\n",
        "    pred_df['Date'] = ids\n",
        "\n",
        "\n",
        "    return pred_df\n",
        "\n",
        "# Specifying the folder path in which CSV files are stored\n",
        "folder_path = \"/kaggle/input/mine-the-model-2023/Upload-Dataset/TRAIN\"\n",
        "dfs = []\n",
        "\n",
        "# Passing each CSV file in the defined function to generate prices for each stock\n",
        "for filename in os.listdir(folder_path):\n",
        "    stock_df = os.path.join(folder_path, filename)\n",
        "    dfs.append(predictor(stock_df))\n",
        "\n",
        "# Concatenating the predicted data into one CSV file and saving it\n",
        "dfs_concat = pd.concat(dfs)\n",
        "dfs_concat.columns = ['ID', 'Price']\n",
        "dfs_concat.to_csv('Submission_prophet.csv', index=False)\n",
        "\n",
        "\n",
        "\n",
        "# Visualizing Predicted Data for one stock using Plotly\n",
        "fig = px.line(dfs_concat[0:100], x='ID', y='Price', title='Closing Price v/s Time')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Closing Price')\n",
        "fig.update_layout(width=1000, height=600)  # Adjust the figure size\n",
        "fig.show()\"\"\"\n"
      ],
      "metadata": {
        "id": "RzpVkYD4WEjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fib(f1,f2,n):\n",
        "  print( f1,  end=\"  \")\n",
        "  print(f2, end=\"  \")\n",
        "  for i in range(n-2):\n",
        "    nxt=f1+f2\n",
        "    print(nxt, end=\"  \")\n",
        "    f1=f2\n",
        "    f2=nxt\n",
        "f1=eval(input(\"Enter the First Number: \"))\n",
        "f2=eval(input(\"Enter the Second Number: \"))\n",
        "n=eval(input(\"Enter the Total Number of elements in Series: \"))\n",
        "fib(3,5,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWT585EYzpRX",
        "outputId": "7cc7df19-b11d-4c10-c6db-8f004b3bba19"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the First Number: 6\n",
            "Enter the Second Number: 9\n",
            "Enter the Total Number of elements in Series: 10\n",
            "3  5  8  13  21  34  55  89  144  233  "
          ]
        }
      ]
    }
  ]
}